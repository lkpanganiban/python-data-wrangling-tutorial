# Web Scraping and Data Wrangling with Python

The following repository is an introduction to web scraping and data wrangling. This will go over the basic workflow of web scraping and data wrangling.

## General Usage and Setup
1. This uses `Jupyter Notebook` as the main tool to execute the various notebooks. This requires that the participant will install the necessary requirements in their own machine. This repository contains a `requirements.txt` file where the dependencies are listed.
2. The participant may opt to use [Google Colab](https://colab.research.google.com/) to run this notebook (this requires a google account). The `Google Colab` already contains the necessary tools and environments to run this exercise. 
   - In the `Google Colab` popup, select **Github** and paste the link of this repository. If this popup is not present, select **File** and select **Upload notebook**.
   - Click **Copy to Drive**, this will create a **Colab folder** in your Google Drive.

## Libraries
The following libraries were used to run these exercises.
- Beautifulsoup4
- Pandas
- Matplotlib 