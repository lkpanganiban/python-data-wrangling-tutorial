{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb112202",
   "metadata": {},
   "source": [
    "# Data Wrangling\n",
    "\n",
    "**Welcome to the Data Wrangling Notebook!**\n",
    "\n",
    "The notebook showcases the power of Python to scrape data from the internet. We will use the libraries `pandas` and `matplotlib` to do the following session and exercises.\n",
    "\n",
    "**Note: This is not a definitive guide.**\n",
    "\n",
    "## What is Data Wrangling?\n",
    "Data wrangling is the process of cleaning, organizing, structuring, and enriching raw data to make it more accessible and useful for analysis and visualization purposes. It involves converting and plotting data from one \"raw\" form into another to make it ready for downstream analytics. Data wrangling is becoming increasingly necessary due to the rapid expansion of the amount of data and data sources available today. It involves removing errors and combining complex data sets to make them more accessible and easier to analyze. The wrangling process encompasses all the practices used to ensure that data is high quality and useful for analytics.\n",
    "\n",
    "### Domain Driven Data Wrangling\n",
    "Data wrangling is just one of the tools to work with data. Also equally important is to have your expertise driving your data wrangling and analysis. As they say, **the workflow or tool must not contradict with science of the domain.** When we deliver or create tools or workflows, these must be guided with the principles of the industry that the tool will be used on/with. \n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before we start, you will need to have a basic knowledge of the following technologies\n",
    "\n",
    "- [Python](https://www.python.org/)\n",
    "\n",
    "## Primary Tool\n",
    "The primary libraries or tools that we will be using are `pandas` and `matplotlib`. These libraries allow us to work and visualize with structured data. There are also a number of data wrangling tools and libraries supported by Python.\n",
    "\n",
    "## Hands-on\n",
    "For this tutorial, we will be using the data that we have scraped from the **web scraping** session. We will be creating a **static map** using containing the data GRDP.    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a514f09f",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "We will import the `panas` and `matplotlib` libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "768825a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a0c5b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
